{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430e5c66",
   "metadata": {},
   "source": [
    "# Exploración del conjunto de datos\n",
    "En este notebook exploraremos los datos para poder tomar una decisión sobre el diseño de la solución. En cada sección encontrarás preguntas con la intención de motivar una reflexión sobre su diseño. Mientras que no necesitan ser respondidas explícitamente, les invito a que las utilicen como guía al momento de justificar sus decisiones de diseño y presentar sus resultados.\n",
    "\n",
    "## Datos de entrenamiento\n",
    "En el conjunto de datos tenemos información sobre las *compras* realizadas en una tienda de ropa en linea. En la siguiente celda podemos ver las columnas o atributos que tenemos a nuestra disposición.\n",
    "- ¿Tenemos valores faltantes o todas las columans tienen la información completa?\n",
    "- ¿Qué tipos de columnas tenemos y cómo podemos procesarlas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a839528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7289 entries, 0 to 7288\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   purchase_id             7289 non-null   int64  \n",
      " 1   customer_id             7289 non-null   object \n",
      " 2   customer_date_of_birth  7289 non-null   object \n",
      " 3   customer_gender         5738 non-null   object \n",
      " 4   customer_signup_date    7289 non-null   object \n",
      " 5   item_id                 7289 non-null   object \n",
      " 6   item_title              7289 non-null   object \n",
      " 7   item_category           7289 non-null   object \n",
      " 8   item_price              7289 non-null   float64\n",
      " 9   item_img_filename       7289 non-null   object \n",
      " 10  item_avg_rating         7244 non-null   float64\n",
      " 11  item_num_ratings        7289 non-null   int64  \n",
      " 12  item_release_date       7289 non-null   object \n",
      " 13  purchase_timestamp      7289 non-null   object \n",
      " 14  customer_item_views     7289 non-null   int64  \n",
      " 15  purchase_item_rating    1544 non-null   float64\n",
      " 16  purchase_device         7289 non-null   object \n",
      " 17  label                   7289 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(11)\n",
      "memory usage: 1.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['purchase_id', 'customer_id', 'customer_date_of_birth',\n",
       "       'customer_gender', 'customer_signup_date', 'item_id', 'item_title',\n",
       "       'item_category', 'item_price', 'item_img_filename', 'item_avg_rating',\n",
       "       'item_num_ratings', 'item_release_date', 'purchase_timestamp',\n",
       "       'customer_item_views', 'purchase_item_rating', 'purchase_device',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "train_file = \"../../datasets/customer_purchases/customer_purchases_train.csv\"\n",
    "train_file = os.path.abspath(train_file)\n",
    "train_df = pd.read_csv(train_file)\n",
    "\n",
    "train_df.info()\n",
    "train_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0950608f",
   "metadata": {},
   "source": [
    "## Prueba\n",
    "Recuerda que en prueba queremos saber si un cliente existente comprará un produco *no existente*. En el conjunto anterior tenemos columnas que solo tendrán información si se ha generado una compra, ¿Que columnas son estas? ¿Que valores podríamos esperar de las mismas para productos que no han salido a la venta? ¿Tiene sentido usarlas en entrenamiento tal cual? ¿Podemos extraer información valiosa de las mismas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f37e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "test_file = \"../../datasets/customer_purchases/customer_purchases_test.csv\"\n",
    "test_file = os.path.abspath(test_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "test_df.info()\n",
    "test_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367084f",
   "metadata": {},
   "source": [
    "# Visualizar los datos por etiqueta\n",
    "\n",
    "Visualiza las etiquetas del conjunto de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df[\"label\"].value_counts().plot(\n",
    "    kind=\"bar\",\n",
    "    xlabel=\"Label\",\n",
    "    ylabel=\"Cantidad purchase_id\",\n",
    "    title=\"purchase_id por etiqueta\",\n",
    "    figsize=(6,4)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0716b",
   "metadata": {},
   "source": [
    "¿Notas algo extraño?  ¿Podemos entrenar un algoritmo de ML en este dataset tal cual se nos presenta?\n",
    "¿Qué problemas podríamos encontrarnos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2c8d7",
   "metadata": {},
   "source": [
    "## Visualizar estadisticas por producto y por cliente\n",
    "\n",
    "En el dataset solo tenemos información de las *compras*, es decir cada que se repite un `customer_id`, podemos saber cuantas compras ha hecho ese cliente. De la misma manera, contar cuantas veces se repite un `item_id` nos dice cuantas veces se ha comprado ese producto. Utiliza pandas para ver si existen clientes que compran que mayor frecuencia que otros, o productos que se compran mas que otros. Responde:\n",
    "- ¿Consideras que los datos se encuentran balanceados dada la información anterior?\n",
    "- ¿Qué estrategías podrian ser útiles al momento de generar negativos?\n",
    "\n",
    "### Datos por usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de compras por cliente\n",
    "by_customer = train_df[\"customer_id\"].value_counts()\n",
    "print(by_customer.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9503ae",
   "metadata": {},
   "source": [
    "¿Cómo podemos interpretar la información anterior?\n",
    "\n",
    "Visualicemos ahora en una gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e3055",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = by_customer.max()\n",
    "nbuckets = 7\n",
    "increment = max_val // nbuckets\n",
    "\n",
    "bins = []\n",
    "labels = []\n",
    "bins = list(range(0, max_val + increment, increment))\n",
    "labels = [f\"{bins[i]+1}-{bins[i+1]}\" for i in range(len(bins)-1)]\n",
    "\n",
    "\n",
    "customer_by_purchase = train_df['customer_id'].value_counts()\n",
    "customer_buckets = pd.cut(customer_by_purchase, bins=bins, labels=labels)\n",
    "bucket_counts = customer_buckets.value_counts().sort_index()\n",
    "\n",
    "bucket_counts.plot(kind=\"bar\", figsize=(6,4))\n",
    "plt.title(\"Clientes agrupados por número de compras\")\n",
    "plt.xlabel(\"Rango de compras\")\n",
    "plt.ylabel(\"Cantidad de clientes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37da91",
   "metadata": {},
   "source": [
    "### Datos por item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de compras por producto\n",
    "by_item = train_df[\"item_id\"].value_counts()\n",
    "print(by_item.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = by_item.max()\n",
    "nbuckets = 5\n",
    "increment = max_val // nbuckets\n",
    "\n",
    "bins = []\n",
    "labels = []\n",
    "bins = list(range(0, max_val + increment, increment))\n",
    "labels = [f\"{bins[i]+1}-{bins[i+1]}\" for i in range(len(bins)-1)]\n",
    "\n",
    "\n",
    "items_by_purchase = train_df['item_id'].value_counts()\n",
    "item_buckets = pd.cut(items_by_purchase, bins=bins, labels=labels)\n",
    "item_counts = item_buckets.value_counts().sort_index()\n",
    "\n",
    "item_counts.plot(kind=\"bar\", figsize=(6,4))\n",
    "plt.title(\"Productos agrupadas por cantidad de compras\")\n",
    "plt.xlabel(\"Rango de compras\")\n",
    "plt.ylabel(\"Cantidad de clientes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28599171",
   "metadata": {},
   "source": [
    "# Generación ejemplos negativos\n",
    "\n",
    "Como pudiste notar solo tenemos información de compras. Si se deseara realizar un algoritmo de clasificación para productos nuevos, este fallaría al ser entrneado en el dataset original ya que no tendría información de ejemplos negativos. Por lo anterior, este tipo de problemas comunmente se modela como sistemas de recomendación. \n",
    "\n",
    "Otra manera de resolverlo, es generar ejemplos negativos dada la información en el conjunto, por ejemplo sabemos el inventario completo (los `item_id` únicos) y sus atributos, asi como el conjunto completo de clientes (`customer_id` únicos) y para cada cliente sabemos los productos que han comprado, *pero tambien sabemos los que no compraron* si al conjunto de productos completo, le restamos el conjunto de productos que si compró. Esto nos da una señal de ejemplos negativos que podemos usar para clasificación.\n",
    "\n",
    "Dicho esto tienes 2 opciones:\n",
    "1. Investigar sistemas de recomendación tradicionales [(collaborative filtering, content-based filtering etc)](https://www.geeksforgeeks.org/machine-learning/content-based-vs-collaborative-filtering-difference/)\n",
    "2. Modelaro como un sistema de clasificación y generar tus propios ejemplos negativos\n",
    "\n",
    "Son libres de elegir la decisión que prefieran.\n",
    "\n",
    "En el caso de clasificación tenemos que considerar lo siguiente: Para muchos clientes, el conjunto de items no comprados será mucho mayor que el de items comprados. \n",
    "- ¿Qué problemas puedo tener si elijo como negativos todos los no comprados para todos los clientes?\n",
    "- ¿Pueden pensar en diferentes estrategias para generar los negativos?\n",
    "\n",
    "Pueden utilizar el archivo [negative_generation.py](./negative_generation.py) para implementar diferentes estrategias de generación de negativos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52bbc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_clases.proyectos.P01_customer_purchases.negative_generation import gen_all_negatives, gen_random_negatives\n",
    "\n",
    "train_df_neg = gen_random_negatives(train_df,n_per_positive=1)\n",
    "\n",
    "train_df_full = pd.concat((train_df, train_df_neg))\n",
    "# Shuffle para que cuando hagamos el split tengamos de ambos muestras\n",
    "train_df_full = train_df_full.sample(frac=1) # 100%\n",
    "\n",
    "train_df_full[\"label\"].value_counts().plot(\n",
    "    kind=\"bar\",\n",
    "    xlabel=\"Label\",\n",
    "    ylabel=\"Cantidad purchase_id\",\n",
    "    title=\"purchase_id por etiqueta\",\n",
    "    figsize=(6,4)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99eb8e",
   "metadata": {},
   "source": [
    "- ¿Que podemos observar cuando generamos todos los negativos?\n",
    "- ¿Se les ocurre otra manera de elegirlos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(train_df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40e231",
   "metadata": {},
   "source": [
    "## Entregables: Análisis exploratorio\n",
    "Dentro de sus entregables de analisis, intenten responder a las preguntas:\n",
    "- ¿Existen valores faltantes (i.e. NaN / None)? ¿Como proponen manejarlos?\n",
    "- ¿Que atributos pueden ser predictores útiles?\n",
    "- ¿Tenemos etiquetas balanceadas? ¿Cómo van a manejarlas?\n",
    "- ¿Que cantidad de productos existententes vs. nuevos tenemos?\n",
    "- ¿Cuantos clientes tenemos?\n",
    "- ¿Que tipos de datos tenemos y como podemos procesarlos?\n",
    "- ¿Existen correlaciones fuertes entre variables dependientes?\n",
    "- ¿Que correlaciones pueden ver entre las variables dependientes y la independiente?\n",
    "\n",
    "### Bonus:\n",
    "Se otorgarán puntos extra a análisis exploratorios excepcionales que integren diferentes métodos de ML visualizaciones y reconocimientos de patrones más complejos que vayan mas allá de lo propuesto/observado en este notebook.\n",
    "\n",
    "### Recomendaciones generales\n",
    "- Les recomiendo explorar la libreria de [seaborn](https://seaborn.pydata.org/) y las diferentes opciones de visualización que tienen.\n",
    "- Los resultados de este problema dependen en gran medida de los atributos derivados y manejo de datos por lo que les recomiento invertir la mayoría de su tiempo a explorar entrenamiento con diferentes conjuntos de atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5b7ad",
   "metadata": {},
   "source": [
    "## Extracción de atributos\n",
    "\n",
    "Podemos extraer atributos del cliente para utilizar tanto en entrenamiento como validación o prueba. utilicen las celdas de abajo para lo mismo y guardar los datos en `customer_feat.csv`. Posteriormente podemos usar estos atributos junto con los de los items existentes asi como nuevos para entrenar y posteriormente predecir.\n",
    "\n",
    "Puedes reemplazar tu eleccion de extracción de atributos en [data_processing.py -> extract_customer_features](./data_processing.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b81681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7289, 18)\n",
      "df saved to D:\\ml25_escuelita\\src\\ml25\\P01_customer_purchases\\boilerplate\\data_processing.py\\..\\..\\..\\datasets\\customer_purchases\\customer_features.csv\n",
      "df saved to D:\\ml25_escuelita\\src\\ml25\\P01_customer_purchases\\boilerplate\\data_processing.py\\..\\..\\..\\datasets\\customer_purchases\\customer_features.csv\n",
      "(7289, 71)\n",
      "cat_featores: ['customer_gender_female', 'customer_gender_male', 'customer_gender_nan', 'item_category_blouse', 'item_category_dress', 'item_category_jacket', 'item_category_jeans', 'item_category_shirt', 'item_category_shoes', 'item_category_skirt', 'item_category_slacks', 'item_category_suit', 'item_category_t-shirt', 'item_img_filename_imgb.jpg', 'item_img_filename_imgbl.jpg', 'item_img_filename_imgg.jpg', 'item_img_filename_imgo.jpg', 'item_img_filename_imgp.jpg', 'item_img_filename_imgr.jpg', 'item_img_filename_imgw.jpg', 'item_img_filename_imgy.jpg']\n",
      "processed array shape: (7289, 89)\n",
      "df saved to D:\\ml25_escuelita\\src\\ml25\\P01_customer_purchases\\boilerplate\\data_processing.py\\..\\..\\..\\datasets\\customer_purchases\\processed_train.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7289 entries, 0 to 7288\n",
      "Data columns (total 72 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   customer_gender_female       7289 non-null   object\n",
      " 1   customer_gender_male         7289 non-null   object\n",
      " 2   age                          7289 non-null   object\n",
      " 3   customer_seniority           7289 non-null   object\n",
      " 4   avg_days_between_purchases   7289 non-null   object\n",
      " 5   days_since_last_purchase     7289 non-null   object\n",
      " 6   avg_purchase_cost            7289 non-null   object\n",
      " 7   std_purchase_cost            7289 non-null   object\n",
      " 8   cat_pct_blouse               7289 non-null   object\n",
      " 9   cat_pct_dress                7289 non-null   object\n",
      " 10  cat_pct_jacket               7289 non-null   object\n",
      " 11  cat_pct_jeans                7289 non-null   object\n",
      " 12  cat_pct_shirt                7289 non-null   object\n",
      " 13  cat_pct_shoes                7289 non-null   object\n",
      " 14  cat_pct_skirt                7289 non-null   object\n",
      " 15  cat_pct_slacks               7289 non-null   object\n",
      " 16  cat_pct_suit                 7289 non-null   object\n",
      " 17  cat_pct_t-shirt              7289 non-null   object\n",
      " 18  color_pct_b                  7289 non-null   object\n",
      " 19  color_pct_bl                 7289 non-null   object\n",
      " 20  color_pct_g                  7289 non-null   object\n",
      " 21  color_pct_o                  7289 non-null   object\n",
      " 22  color_pct_p                  7289 non-null   object\n",
      " 23  color_pct_r                  7289 non-null   object\n",
      " 24  color_pct_w                  7289 non-null   object\n",
      " 25  color_pct_y                  7289 non-null   object\n",
      " 26  autumn                       7289 non-null   object\n",
      " 27  spring                       7289 non-null   object\n",
      " 28  summer                       7289 non-null   object\n",
      " 29  winter                       7289 non-null   object\n",
      " 30  exclusive                    7289 non-null   object\n",
      " 31  casual                       7289 non-null   object\n",
      " 32  stylish                      7289 non-null   object\n",
      " 33  elegant                      7289 non-null   object\n",
      " 34  durable                      7289 non-null   object\n",
      " 35  classic                      7289 non-null   object\n",
      " 36  lightweight                  7289 non-null   object\n",
      " 37  modern                       7289 non-null   object\n",
      " 38  premium                      7289 non-null   object\n",
      " 39  item_category_blouse         7289 non-null   object\n",
      " 40  item_category_dress          7289 non-null   object\n",
      " 41  item_category_jacket         7289 non-null   object\n",
      " 42  item_category_jeans          7289 non-null   object\n",
      " 43  item_category_shirt          7289 non-null   object\n",
      " 44  item_category_shoes          7289 non-null   object\n",
      " 45  item_category_skirt          7289 non-null   object\n",
      " 46  item_category_slacks         7289 non-null   object\n",
      " 47  item_category_suit           7289 non-null   object\n",
      " 48  item_category_t-shirt        7289 non-null   object\n",
      " 49  exclusive_in_title           7289 non-null   object\n",
      " 50  casual_in_title              7289 non-null   object\n",
      " 51  stylish_in_title             7289 non-null   object\n",
      " 52  elegant_in_title             7289 non-null   object\n",
      " 53  durable_in_title             7289 non-null   object\n",
      " 54  classic_in_title             7289 non-null   object\n",
      " 55  lightweight_in_title         7289 non-null   object\n",
      " 56  modern_in_title              7289 non-null   object\n",
      " 57  premium_in_title             7289 non-null   object\n",
      " 58  item_img_filename_imgb.jpg   7289 non-null   object\n",
      " 59  item_img_filename_imgbl.jpg  7289 non-null   object\n",
      " 60  item_img_filename_imgg.jpg   7289 non-null   object\n",
      " 61  item_img_filename_imgo.jpg   7289 non-null   object\n",
      " 62  item_img_filename_imgp.jpg   7289 non-null   object\n",
      " 63  item_img_filename_imgr.jpg   7289 non-null   object\n",
      " 64  item_img_filename_imgw.jpg   7289 non-null   object\n",
      " 65  item_img_filename_imgy.jpg   7289 non-null   object\n",
      " 66  item_price                   7289 non-null   object\n",
      " 67  season_spring                7289 non-null   object\n",
      " 68  season_summer                7289 non-null   object\n",
      " 69  season_autumn                7289 non-null   object\n",
      " 70  season_winter                7289 non-null   object\n",
      " 71  label                        7289 non-null   object\n",
      "dtypes: object(72)\n",
      "memory usage: 4.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from data_processing import *\n",
    "\n",
    "print(train_df.shape)\n",
    "\n",
    "customer_features = extract_customer_features(train_df)\n",
    "merged_train_df = merge_customer_profiles(train_df, customer_features)\n",
    "\n",
    "processed_df = preprocess(train_df, training=True)\n",
    "print(processed_df.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
